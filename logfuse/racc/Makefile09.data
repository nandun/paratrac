################################################################################
##
## Organization:
##   1. Variable definitions
##   2. Rules
##     2.1 Rules common to MEDIE/Info-PubMed
##     2.2 Rules for MEDIE
##     2.3 Rules for Info-PubMed
##     2.4 Rules for export data
##     2.A Rules for merged txt-tbl
##
################################################################################

## TODO: 
##   - draw presumed directory configuration

RM = rm

################################################################################
##
## Section 1: Variable definitions
##
################################################################################

##------------------------------------------------------------------------------
## PubMed data spec.
##------------------------------------------------------------------------------

### last-two-digits of the current year
YEAR=08

### last ID of the baseline files and first ID of the update data files
#-> 2008: 0563
#-> 2009: 0593
LAST_BASELINE_ID = 0563

# LAST_YEAR = YEAR - 1
# FIRST_UPDATE_ID = LAST_BASELINE_ID + 1
LAST_YEAR = $(shell printf "%02d" $$((20$(YEAR) - 2000 - 1)))
FIRST_UPDATE_ID = $(shell printf "%04d" $$((1$(LAST_BASELINE_ID) - 10000 + 1)))

##------------------------------------------------------------------------------
## System-specific settings
##------------------------------------------------------------------------------

### Generic tools
PERL = /usr/bin/perl
MD5  = /usr/bin/md5sum
RUBY = /usr/bin/ruby

### path to g++ 4.3.0 (or later) shared libraries; for gene-ner
GXX430_LIBPATH = /usr/local/gcc/lib64:/usr/local/gcc/lib

##------------------------------------------------------------------------------
## Directory configuration
##------------------------------------------------------------------------------

### Data processing root directory
ROOT = .

### Where the NLP modules live
PROG_DIR = $(ROOT)/tools

### Where to find the original pubmed XML files (both of baseline and update)
###   NOTE: it is assumed that the download XML files have the same time-stamps
###   as ones on NLM's ftp server; it is important to show correct last-update 
###   dates to the MEDIE/info-pubmed users, which is a requirement from NLM.
# ORIG_DIR=/works/fauchon4/y-matsu/PubMed2007/baseline
# ORIG_DIR=/home/zonen/corpus/PubMed2008
# ORIG_DIR = /works/fauchon4/wxc/PubMed2008
ORIG_DIR = $(ROOT)/pubmed-20$(YEAR)

### Where to create intermediate and output files
# OUT_DIR_BASE=.
# OUT_DIR_BASE = /works/mlesna2a/fauchon7.bak20081029/wxc/work
# OUT_DIR_BASE = /works/fauchon4/wxc/work
OUT_DIR_BASE = $(ROOT)/data-20$(YEAR)

### Base-directory for last year's output files
# PREV_OUT_DIR_BASE = /works/fauchon1/wxc/work
# PREV_OUT_DIR_BASE = /works/fauchon6/wxc/data-20071125
PREV_OUT_DIR_BASE = $(ROOT)/data-20$(LAST_YEAR)

### Base-directory for this year's output files
CURR_OUT_DIR_BASE = $(OUT_DIR_BASE)

### ARTICLE_TBL_BASE : Where to put annual baseline/all txt-tbl files
### EXPORT_WORK_DIR  : Where to put export data
### WORK_BASE        : Where to httpd log, temporary data etc.
ARTICLE_TBL_BASE = $(OUT_DIR_BASE)/article-tables
EXPORT_BASE      = $(OUT_DIR_BASE)/export
WORK_BASE        = $(OUT_DIR_BASE)/work

### Export server setting
EXPORT_SERVER_DIR  = $(PROG_DIR)/thttpd
EXPORT_SERVER_PORT = 10080
EXPORT_SERVER_LOG  = $(WORK_BASE)/httpd.log
EXPORT_SERVER_PID  = $(WORK_BASE)/httpd.pid

##------------------------------------------------------------------------------
## Processing type switches
##------------------------------------------------------------------------------

## if WEEKLY_UPDATE = 0, do weekly update; otherwise do annual update
WEEKLY_UPDATE = 0

## if PARALLEL_PARSING = 1, parse all text without re-using old parse results
PARALLEL_PARSING = 0

## if DO_* = 0, some of the dependencies are ignored
DO_TBL         = 1
DO_IMPORT      = 1
DO_BIB         = 1
DO_SS          = 1
DO_EX_TXT      = 1
DO_EX_ENJU     = 1
DO_ENJU        = 1
DO_KSDEP       = 1
DO_GENE_NE     = 1
DO_OTHER_NE    = 1
DO_MERGE       = 1
DO_EE          = 1
DO_STAG        = 1
DO_PPI         = 1
DO_DGA         = 1
DO_COOCC       = 1
DO_ICONVERTER  = 1
DO_MEDIE_INPUT = 1
DO_MEDIE_DB    = 1
DO_EXPORT      = 1

##------------------------------------------------------------------------------
## Target file
##------------------------------------------------------------------------------
ID=0001
FILE_ID=medline$(YEAR)n$(ID)

##------------------------------------------------------------------------------
## Programs & config/data files
##------------------------------------------------------------------------------

### medline2medie package
M2M_DIR = $(PROG_DIR)/medline2medie

### Standoff manager
SOM_DIR   = $(PROG_DIR)/StandOffManager
SOM       = $(SOM_DIR)/som
TAG_ORDER = $(SOM_DIR)/script/tagOrder.enju-2_2.tag 
CLIP_TAG  = $(SOM_DIR)/script/tagsToClip.tag

### Sentence splitter
GENIASS_DIR     = $(PROG_DIR)/geniass
GENIASS         = $(GENIASS_DIR)/run_geniass.sh
MAKE_MAPPING    = $(GENIASS_DIR)/makeMapping
REMAP_STAND_OFF = $(GENIASS_DIR)/remapStandOff

### Enju
ENJU = $(PROG_DIR)/enju/run-enju -so -genia

### Gene NER
GENE_NER_ENV      = env LD_LIBRARY_PATH=$(GXX430_LIBPATH):$$LD_LIBRARY_PATH 
GENE_NER_DIR      = $(PROG_DIR)/MEDIE_NER
GENE_NER          = $(GENE_NER_ENV) $(GENE_NER_DIR)/MedT_NER/medt_ner
NER_POST_FILTER   = $(GENE_NER_ENV) $(GENE_NER_DIR)/filter_words/filter_words
GENE_NE_THRESHOLD = 0.015

GENE_NER_FILTER_OPTS=\
         -tag  Article \
         -a    filter \
         -thr  0.0 \
         -m    $(GENE_NER_DIR)/model/filter.output \
         -s    $(GENE_NER_DIR)/model/filter.dict \
         -init $(GENE_NER_DIR)/model/gena.mtn

GENE_NER_DISAMB_OPTS=\
         -tag  Article \
         -a    rdisamb \
         -m    $(GENE_NER_DIR)/model/disamb.output \
         -s    $(GENE_NER_DIR)/model/disamb.dict \
         -init $(GENE_NER_DIR)/model/gena.mtn

NER_POST_FILTER_OPTS=\
         -w $(GENE_NER_DIR)/filter_words/stop_word.txt \
         -p $(GENE_NER_DIR)/filter_words/stop_pos.txt

### Disease NER
OTHER_NER_DIR    = $(PROG_DIR)/disease_longest_ner
OTHER_NER_BIN    = $(OTHER_NER_DIR)/longest_ner
OTHER_NER_FORMAT = $(OTHER_NER_DIR)/facta_ne_format.txt
OTHER_NER_DICT   = $(OTHER_NER_DIR)/facta_dict.ln
OTHER_NER = $(OTHER_NER_BIN) -format $(OTHER_NER_FORMAT) -usedict $(OTHER_NER_DICT)

### Gena Dictionary:
GENA_DICT_DIR = $(PROG_DIR)/Gena-20051011

### source impact factor file
# SRC_IFACTOR_FILE = $(M2M_DIR)/ifactor2005.txt

### Small scripts
ADD_LEX_HEAD        = $(PERL) $(M2M_DIR)/add_lex_head.perl
COMPATIBLE          = $(PERL) $(M2M_DIR)/compatible.perl
MERGE_ENJU_OUTPUT   = $(PERL) $(M2M_DIR)/merge_enju_output.perl
BIB_TAGGER          = $(PERL) $(M2M_DIR)/bib_tagger.perl $(M2M_DIR)/bib_pubmed.dat
CHANGE_ID           = $(PERL) $(M2M_DIR)/change_id.perl
CREATE_IFACTOR      = $(PERL) $(M2M_DIR)/createIFfile.perl
MAKE_ARTICLE_TABLE  = $(PERL) $(M2M_DIR)/make_tbl_one.09
MERGE_ARTICLE_TABLE = $(PERL) $(M2M_DIR)/merge_txt_tbl.perl
MAKE_ENJU_SRC       = $(PERL) $(M2M_DIR)/make_enju_src.09
MAKE_ENJU_SO        = $(PERL) $(M2M_DIR)/make_enju_so.09
MAKE_ENJU_SO_IDX    = $(PERL) $(M2M_DIR)/make_enju_so_idx.perl
RUNE_CONFIG         = $(PERL) $(M2M_DIR)/runeconf.prl
SORT_BY_ARTICLE     = $(PERL) $(M2M_DIR)/sort_by_article.perl
MERGE_GENA_DATA     = $(PERL) $(M2M_DIR)/merge_gena_data.perl
DEP2SO              = $(PERL) $(M2M_DIR)/dep2so.prl
POS2CONLL           = $(PERL) $(M2M_DIR)/pos2conll.prl
MAKE_STAGGER_INPUT       = $(PERL) $(M2M_DIR)/make_stagger_input.perl
MERGE_STAGGER_OUTPUT     = $(PERL) $(M2M_DIR)/merge_stagger_output.perl
EXTRACT_SENTENCE_TEXT    = $(PERL) $(M2M_DIR)/extract_sentence_text.perl
# GENE_NE_THRESHOLD_FILTER = $(PERL) $(M2M_DIR)/filter_gene_ne.perl
GENE_NE_THRESHOLD_FILTER = $(PERL) $(M2M_DIR)/confidence_filter.perl filter_confidence
MAKE_SUMMARY_REC         = $(PERL) $(M2M_DIR)/make_summary_rec.perl

### Genia tagger
GENIA_TAGGER = (cd $(PROG_DIR)/geniatagger && ./geniatagger)

### Rune new PPI program
AKANE_PPI_PATH = $(PROG_DIR)/AkanePPI
AKANE_PPI      = $(AKANE_PPI_PATH)/akane
AKANE_MODEL    = $(AKANE_PPI_PATH)/AIMed/Enju_TK_Words.linear.model

PPI_THRESHOLD_FILTER = $(PERL) $(M2M_DIR)/confidence_filter.perl confidence
PPI_THRESHOLD = 0

### Kenji dependency parser
KSDEP_PATH  = $(PROG_DIR)/ksdep
KSDEP       = $(KSDEP_PATH)/ksdep
KSDEP_MODEL = $(KSDEP_PATH)/genia.mod

### Event expression tagger
EE_TAGGER_DIR  = $(PROG_DIR)/ee
EE_TAGGER_DICT = $(EE_TAGGER_DIR)/eedict.lst
EE_TAGGER_CONF = $(EE_TAGGER_DIR)/eet.conf
EE_TAGGER      = $(EE_TAGGER_DIR)/eet

### Sentence type tagger
STAGGER = $(PROG_DIR)/abstruct/bin/sentence_tagger.sh

### Medie DB indexer
MAKE_DB     = $(PROG_DIR)/medie-noBDB/makeDB/read-file
DB_ATTRLIST = $(M2M_DIR)/medie.attrlist
DB_SETTING  = $(M2M_DIR)/medie.setting

### DGA recognizer
DGA_DIR           = $(PROG_DIR)/dga
DGA               = $(DGA_DIR)/run_dga.sh
DGA_INPUT_FILTER  = $(PERL) $(DGA_DIR)/input_filter.perl
DGA_OUTPUT_FILTER = $(PERL) $(DGA_DIR)/output_filter.perl

### Post-processor for Info-pubmed
INFOP_DIR   = $(PROG_DIR)/info-pubmed
FIND_COOCC  = $(INFOP_DIR)/WEB-INF/src/C++/FindCoocc/find_coocc
ICONVERTER  = $(INFOP_DIR)/WEB-INF/src/C++/IConverter/IConverter
COLLECT_DEL = $(PERL) $(INFOP_DIR)/WEB-INF/script/collect_del.prl

##------------------------------------------------------------------------------
## Output directory
##------------------------------------------------------------------------------

### Default output directory for all modules' output and temporaly files
OUT_DIR = $(OUT_DIR_BASE)/$(FILE_ID)

##------------------------------------------------------------------------------
## Data files (to keep)
##------------------------------------------------------------------------------

###*************************************
### Merged article table files
###  - PREV_ALL_TBL_GZ: last year's records (baseline + update)
###  - CURR_BASELINE_TBL_GZ: this year's baseline records
###*************************************
PREV_ALL_TBL_GZ      = $(ARTICLE_TBL_BASE)/20$(LAST_YEAR).all.txt-tbl.gz
CURR_BASELINE_TBL_GZ = $(ARTICLE_TBL_BASE)/20$(YEAR).baseline.txt-tbl.gz

###*************************************
### Source XML and its md5 check sum
###*************************************
PUBMED_XML_GZ     = $(ORIG_DIR)/$(FILE_ID).xml.gz
PUBMED_XML_GZ_MD5 = $(ORIG_DIR)/$(FILE_ID).xml.gz.md5

###*************************************
### Imported data
###*************************************
IMPORT_DIR    = $(OUT_DIR)
PUBMED_TXT_GZ = $(IMPORT_DIR)/$(FILE_ID).txt.gz
PUBMED_SO_GZ  = $(IMPORT_DIR)/$(FILE_ID).so.gz

###*************************************
### Clipped ArticleTitle and AbstratText
###*************************************
ABST_TXT_GZ = $(IMPORT_DIR)/$(FILE_ID).abst.txt.gz
ABST_SO_GZ  = $(IMPORT_DIR)/$(FILE_ID).abst.so.gz

###*************************************
### Files for persimonious processing
###  - TXT_TBL: position of text regions (ArticleTitle and AbstratText)
###  - SO_SRC:  source position of the text regions
###  - EX_TXT:  extracted new text 
###*************************************
TXT_TBL_GZ = $(IMPORT_DIR)/$(FILE_ID).txt-tbl.gz
SO_SRC_GZ  = $(IMPORT_DIR)/$(FILE_ID).so-src.gz
EX_TXT_GZ  = $(IMPORT_DIR)/$(FILE_ID).ex.txt.gz

###----------------------------------------------------
###
### Output of single modules
###
###----------------------------------------------------

###*************************************
### Sentence splitter's output
###  - *_SS_GZ  : 1-sentence-per-line format data
###  - *_SS_MAP : position mapping information before/after the ssplit
###*************************************
SS_OUT_DIR  = $(OUT_DIR)
ABST_SS_GZ  = $(SS_OUT_DIR)/$(FILE_ID).abst.ss.gz
ABST_SS_MAP = $(SS_OUT_DIR)/$(FILE_ID).abst.ss.map
EX_SS_GZ    = $(SS_OUT_DIR)/$(FILE_ID).ex.ss.gz
EX_SS_MAP   = $(SS_OUT_DIR)/$(FILE_ID).ex.ss.map

###*************************************
### Enju's output
###*************************************
ENJU_OUT_DIR = $(OUT_DIR)

### Files for parallel HPSG parsing
###  - SUBFILE_LIST:   list of divided enju-input files
###  - READY_TO_MERGE: time-stamp file to remember the finish time of parsing
SUBFILE_LIST   = $(ENJU_OUT_DIR)/$(FILE_ID).abst.ss.subfile-list
READY_TO_MERGE = $(ENJU_OUT_DIR)/$(FILE_ID).abst.ss.ready-to-merge

### Parse results on abst.ss
###  - *_SS_ENJU_SO_GZ : parse results on *.ss
###  - EX_ENJU_SO_GZ   : parse results on ex.txt
ABST_SS_ENJU_SO_GZ = $(ENJU_OUT_DIR)/$(FILE_ID).abst.ss.enju.so.gz
EX_SS_ENJU_SO_GZ = $(ENJU_OUT_DIR)/$(FILE_ID).ex.ss.enju.so.gz
EX_ENJU_SO_GZ    = $(ENJU_OUT_DIR)/$(FILE_ID).ex.enju.so.gz

### Indexed parse results on pubmed.txt
ENJU_SO_SUFFIX = .enju.so
ENJU_SO_IDX    = $(ENJU_OUT_DIR)/$(FILE_ID)$(ENJU_SO_SUFFIX).idx
ENJU_SO_DAT    = $(ENJU_OUT_DIR)/$(FILE_ID)$(ENJU_SO_SUFFIX).dat

###*************************************
### Kenji's dependency parser
###*************************************
KSDEP_OUT_DIR = $(OUT_DIR)

## Parse results
##  - *_SS_KSDEP_OUT_GZ : parse results on *.ss in conll format
##  - *_SS_KSDEP_SO_GZ  : parse results on *.ss in standoff format
##  - *_KSDEP_SO_GZ     : parse results on *.txt in standoff format
ABST_SS_KSDEP_OUT_GZ = $(KSDEP_OUT_DIR)/$(FILE_ID).abst.ss.ksdep.out.gz
ABST_SS_KSDEP_SO_GZ  = $(KSDEP_OUT_DIR)/$(FILE_ID).abst.ss.ksdep.so.gz
EX_SS_KSDEP_OUT_GZ   = $(KSDEP_OUT_DIR)/$(FILE_ID).ex.ss.ksdep.out.gz
EX_SS_KSDEP_SO_GZ    = $(KSDEP_OUT_DIR)/$(FILE_ID).ex.ss.ksdep.so.gz
EX_KSDEP_SO_GZ       = $(KSDEP_OUT_DIR)/$(FILE_ID).ex.ksdep.so.gz

### Indexed ksdep-so file
KSDEP_SO_SUFFIX = .ksdep.so
KSDEP_SO_IDX    = $(KSDEP_OUT_DIR)/$(FILE_ID)$(KSDEP_SO_SUFFIX).idx
KSDEP_SO_DAT    = $(KSDEP_OUT_DIR)/$(FILE_ID)$(KSDEP_SO_SUFFIX).dat

###*************************************
### Gene-NER's output: before/after thresholding
###*************************************
GENE_NE_OUT_DIR   = $(OUT_DIR)
GENE_NE_ALL_SO_GZ = $(GENE_NE_OUT_DIR)/$(FILE_ID).gene-ne-all.so.gz
GENE_NE_SO_GZ     = $(GENE_NE_OUT_DIR)/$(FILE_ID).gene-ne.so.gz

###*************************************
### Disease-NER's output
## Disease-NER => Other-NER : 2008.11.10
## DISEASE_NE_DAT_GZ=$(DISEASE_NE_OUT_DIR)/$(FILE_ID).disease-ne.dat.gz
## DISEASE_NE_SO_GZ=$(DISEASE_NE_OUT_DIR)/$(FILE_ID).disease-ne.so.gz
###*************************************
OTHER_NE_OUT_DIR = $(OUT_DIR)
OTHER_NE_SO_GZ   = $(OTHER_NE_OUT_DIR)/$(FILE_ID).other-ne.so.gz

###*************************************
### Event expression data
###*************************************
EE_OUT_DIR = $(OUT_DIR)
EE_SO_GZ   = $(EE_OUT_DIR)/$(FILE_ID).ee.so.gz

###*************************************
### Sentence type data
###*************************************
STAG_OUT_DIR = $(OUT_DIR)
STAG_SO_GZ   = $(STAG_OUT_DIR)/$(FILE_ID).stag.so.gz

# ###*************************************
# ### Impact factor data -- deleted by a license issue (2008.12.12, matuzaki)
# ###*************************************
# IFACTOR_OUT_DIR = $(OUT_DIR)
# IFACTOR_TXT     = $(IFACTOR_OUT_DIR)/ifactor_$(ID).txt

###*************************************
### bibliographical data
###*************************************
BIB_OUT_DIR = $(OUT_DIR)
BIB_SO      = $(BIB_OUT_DIR)/$(FILE_ID).bib.so

###*************************************
### PPI config, output and log file
###*************************************
PPI_OUT_DIR     = $(OUT_DIR)
PPI_SO_GZ       = $(PPI_OUT_DIR)/$(FILE_ID).ppi.so.gz
AKANE_LOG       = $(PPI_OUT_DIR)/$(FILE_ID).akane.log
RUNE_CONFIG_XML = $(PPI_OUT_DIR)/$(FILE_ID).runeconf.xml

###*************************************
### DGA output 
###*************************************
DGA_OUT_DIR = $(OUT_DIR)
DGA_SO_GZ   = $(DGA_OUT_DIR)/$(FILE_ID).dga.so.gz

###*************************************
### Co-occurrence data
###*************************************
COOCC_OUT_DIR = $(OUT_DIR)
COOCC_SO_GZ   = $(COOCC_OUT_DIR)/$(FILE_ID).coocc.so.gz

###
### Merged annotation data
###

### pubmed-meta-tag + enju + gene-ne + disease-ne + event_expression,
### + sentence_type
### + post-processing for backward-compatibility 
### + medie-specific modifications
MEDIE_INPUT_OUT_DIR = $(OUT_DIR)
MEDIE_INPUT_XML_GZ  = $(MEDIE_INPUT_OUT_DIR)/$(FILE_ID).medie-input.xml.gz


###
### Database files
###

### MEDIE DB output directory
DB_OUT_DIR = $(OUT_DIR)/medie_db

### Log file of medie-DB indexer
MAKE_DB_LOG        = $(DB_OUT_DIR)/$(FILE_ID).make_db.log
MEDIE_DB_TIMESTAMP = $(DB_OUT_DIR)/$(FILE_ID).medie_db.time-stamp

### Update summary record:
###   <file> ::= <time-stamp> '\t' <new> '\t' <update> '\t' <delete>'\n'
###       <time-stamp> : time-stamp of input XML
###       <new>        : number of new articles
###       <update>     : number of updated articles
###       <delete>     : number of deleted articles
UPDATE_SUMMARY = $(OUT_DIR)/$(FILE_ID).summary

### Deleted/over-ridden article data file (weekly update)
DEL_OUT_DIR = $(OUT_DIR)
DEL_GZ      = $(DEL_OUT_DIR)/$(FILE_ID).del.gz

### Info-pubmed DB source file (output of IConverter) and
### Deleted-citation data
ICONVERTER_OUT_DIR = $(OUT_DIR)
PREOUT             = $(ICONVERTER_OUT_DIR)/$(FILE_ID).preout
DELCIT             = $(ICONVERTER_OUT_DIR)/$(FILE_ID).delcit

### Exported data tarball
EXPORT_TGZ = $(EXPORT_BASE)/$(FILE_ID).export.tgz

##------------------------------------------------------------------------------
## Intermediate Files
##------------------------------------------------------------------------------
#--- temporalily gunzip'ed files
PUBMED_TXT = $(OUT_DIR)/$(FILE_ID).txt
PUBMED_SO  = $(OUT_DIR)/$(FILE_ID).so
ABST_TXT   = $(OUT_DIR)/$(FILE_ID).abst.txt
ABST_SO    = $(OUT_DIR)/$(FILE_ID).abst.so
ABST_SS    = $(OUT_DIR)/$(FILE_ID).abst.ss
EX_TXT     = $(OUT_DIR)/$(FILE_ID).ex.txt
EX_SS      = $(OUT_DIR)/$(FILE_ID).ex.ss

INTER += $(PUBMED_TXT)
INTER += $(PUBMED_SO)
INTER += $(ABST_TXT)
INTER += $(ABST_SO)
INTER += $(ABST_SS)
INTER += $(EX_TXT)
INTER += $(EX_SS)

ENJU_SO     = $(OUT_DIR)/$(FILE_ID).enju.so
KSDEP_SO    = $(OUT_DIR)/$(FILE_ID).ksdep.so
GENE_NE_SO  = $(OUT_DIR)/$(FILE_ID).gene-ne.so
OTHER_NE_SO = $(OUT_DIR)/$(FILE_ID).other-ne.so
EE_SO       = $(OUT_DIR)/$(FILE_ID).ee.so
STAG_SO     = $(OUT_DIR)/$(FILE_ID).stag.so
PPI_SO      = $(OUT_DIR)/$(FILE_ID).ppi.so

INTER += $(ENJU_SO)
INTER += $(KSDEP_SO)
INTER += $(GENE_NE_SO)
INTER += $(OTHER_NE_SO)
INTER += $(EE_SO)
INTER += $(STAG_SO)
INTER += $(PPI_SO)

### Parse results on pubmed.txt; not indexed
###  * This file is intentionally named differently from .enju.so.gz,
### to avoid accidentally delete old .enju.so.gz files
ENJU_SO_RAW_GZ = $(OUT_DIR)/$(FILE_ID).enju.so.raw.gz

### Parse results on pubmed.txt; not indexed
KSDEP_SO_RAW_GZ = $(OUT_DIR)/$(FILE_ID).ksdep.so.raw.gz

INTER += $(ENJU_SO_RAW_GZ)
INTER += $(KSDEP_SO_RAW_GZ)

#--- various kind of merged .so and .xml files
ALL_NE_SO              = $(OUT_DIR)/$(FILE_ID).all-ne.so
ENJU_NE_SO_GZ          = $(OUT_DIR)/$(FILE_ID).enju-ne.so.gz
PUBMED_ENJU_NE_SO_GZ   = $(OUT_DIR)/$(FILE_ID).pubmed-enju-ne.so.gz
PPI_INPUT_SO           = $(OUT_DIR)/$(FILE_ID).ppi-input.so
ICONVERTER_INPUT_SO_GZ = $(OUT_DIR)/$(FILE_ID).iconverter-input.so.gz
MEDIE_INPUT_XML        = $(OUT_DIR)/$(FILE_ID).medie-input.xml
MEDIE_INPUT_SO_GZ      = $(OUT_DIR)/$(FILE_ID).medie-input.so.gz

INTER += $(ALL_NE_SO)
INTER += $(ENJU_NE_SO_GZ)
INTER += $(PUBMED_ENJU_NE_SO_GZ)
INTER += $(PPI_INPUT_SO)
INTER += $(ICONVERTER_INPUT_SO_GZ)
INTER += $(MEDIE_INPUT_XML)
INTER += $(MEDIE_INPUT_SO_GZ)
 
#--- intermediate files for Gene-NER/Other-NER
GENE_NE_FILTER_SO = $(OUT_DIR)/$(FILE_ID).gene-ne-filter.so
GENE_NE_DISAMB_SO = $(OUT_DIR)/$(FILE_ID).gene-ne-disamb.so
OTHER_NE_MATCH_SO = $(OUT_DIR)/$(FILE_ID).other-ne-match.so

INTER += $(GENE_NE_FILTER_SO)
INTER += $(GENE_NE_DISAMB_SO)
INTER += $(OTHER_NE_MATCH_SO)

##------------------------------------------------------------------------------
## Runtime configuration
##------------------------------------------------------------------------------
ifneq ($(RUNTIME_CONF),)
include $(RUNTIME_CONF)
endif

##------------------------------------------------------------------------------
## Intermediate file decl.
##------------------------------------------------------------------------------
.INTERMEDIATE: $(INTER)

##------------------------------------------------------------------------------
## Utility macros
##------------------------------------------------------------------------------

###
### Usage: @$(BEGIN_STEP)
###        @$(END_STEP)
###    write begin/end message of a rule execution
###
define BEGIN_STEP
echo "#---------------------------------------------------------------"
echo "# begin: `date`"
echo $^ | xargs -n 1 echo "# source: "
echo $@ | xargs -n 1 echo "# target: "
echo "#---------------------------------------------------------------"
endef

define END_STEP
echo "#---------------------------------------------------------------"
echo "# end: `date`"
echo "#---------------------------------------------------------------"
endef

###
### Usage: $(MY_GZIP) file
###
###   do two things:
###      1. do gzip on 'file.ungz' and name the result 'file'
###      2. remove 'file.ungz'
###
###   note that you cannot use any suffix other than '.ungz'
###
MY_GZIP=sh -c 'gzip -c $$0.ungz > $$0 && $(RM) $$0.ungz' 


###
### Usage:
###    target: deps
###         command-1 | command-2 | ... | command-n > $@ ; $(PCHECK)
###
###  or 
###
###    target: deps
###			command-1 \
###				| command-2 \
###				...
###				| command-n \
###				> $@ \
###             ; $(PCHECK)
###
###    Put the PCHECK on the *same line* (from the viewpoint
###    of shell) as the pipeline.  So, in the second form, never forget 
###    the '\ ; ' between the pipeline and PCHECK.
###
PCHECK=\
if [ `echo $${PIPESTATUS[@]} | tr -d " "` -ne 0 ]; then $(RM) -f $@; exit 1; fi


### Usage example:
### make --no-print-dir -f Makefile09.data \
###      RUNTIME_CONF=your.conf VARNAME=EXPORT_BASE echo
.PHONY: echo
echo:
	@echo $($(VARNAME))

################################################################################
##
##
## Section 2: Rules
##
##
################################################################################

.PHONY: usage_error
usage_error: 
	@echo "You must specify a make-target"
	@exit 1

################################################################################
## phony targets for shorthands and utils
################################################################################
.PHONY: begin_msg end_msg out_dir \
        ex_txt ex_enju_so enju_so \
        preout coocc medie all exp \
		ppi ee dga medie_xml gene_ne other_ne \
		clean_db clean_db_

## Shorthands
ex_txt:     begin_msg out_dir $(TXT_TBL_GZ) $(SO_SRC_GZ) $(EX_TXT_GZ) end_msg
ex_ss:      begin_msg out_dir $(EX_SS_GZ) $(EX_SS_MAP) end_msg
ex_enju_so:  begin_msg out_dir $(EX_ENJU_SO_GZ)  end_msg
ex_ksdep_so: begin_msg out_dir $(EX_KSDEP_SO_GZ) end_msg
enju_so:    begin_msg out_dir $(ENJU_SO_IDX) $(ENJU_SO_DAT) end_msg
ksdep_so:   begin_msg out_dir $(KSDEP_SO_IDX) $(KSDEP_SO_DAT) end_msg

gene_ne:    begin_msg out_dir $(GENE_NE_SO_GZ)  end_msg
other_ne:   begin_msg out_dir $(OTHER_NE_SO_GZ) end_msg
ppi:        begin_msg out_dir $(PPI_SO_GZ)      end_msg
dga:        begin_msg out_dir $(DGA_SO_GZ)      end_msg
ee:         begin_msg out_dir $(EE_SO_GZ)       end_msg
coocc:      begin_msg out_dir $(COOCC_SO_GZ)    end_msg

preout:     begin_msg out_dir $(PREOUT) $(DELCIT)   end_msg
medie_xml:  begin_msg out_dir $(MEDIE_INPUT_XML_GZ) end_msg
medie:      begin_msg out_dir $(MEDIE_DB_TIMESTAMP) end_msg

all:        begin_msg out_dir $(MEDIE_DB_TIMESTAMP) $(PREOUT) $(DELCIT) end_msg
exp:        begin_msg out_dir $(EXPORT_TGZ) end_msg

clean_db:   begin_msg out_dir clean_db_ end_msg

begin_msg :
	@echo "####################################"
	@echo "# BEGIN: `date`"
	@echo "# ID = $(ID)"
	@echo "# OUT_DIR = $(OUT_DIR)"
	@echo "# HOST_NAME = `hostname`"
	@echo "# GOAL = $(MAKECMDGOALS)"
	@echo "####################################"

end_msg :
	@echo "####################################"
	@echo "# END: `date`"
	@echo "####################################"

out_dir :
	@mkdir -p $(OUT_DIR)

clean_db_:
	$(RM) -rf $(DB_OUT_DIR)

################################################################################
##
## Section 2.1: Medie/info-pubmed common processes
##
################################################################################

##------------------------------------------------------------------------------
## gzip file expansion
##------------------------------------------------------------------------------
$(PUBMED_TXT)  : $(PUBMED_TXT_GZ)
	echo '$(PUBMED_TXT_GZ)'
	@$(BEGIN_STEP)
	zcat $^ > $@
$(PUBMED_SO)   : $(PUBMED_SO_GZ)   ; zcat $^ > $@
$(ABST_TXT)    : $(ABST_TXT_GZ)    ; zcat $^ > $@
$(ABST_SO)     : $(ABST_SO_GZ)     ; zcat $^ > $@
$(ABST_SS)     : $(ABST_SS_GZ)     ; zcat $^ > $@
$(EX_TXT)      : $(EX_TXT_GZ)      ; zcat $^ > $@
$(EX_SS)       : $(EX_SS_GZ)       ; zcat $^ > $@

$(ENJU_SO)     : $(ENJU_SO_DAT)    ; zcat $^ > $@
$(KSDEP_SO)    : $(KSDEP_SO_DAT)   ; zcat $^ > $@
$(GENE_NE_SO)  : $(GENE_NE_SO_GZ)  ; zcat $^ > $@
$(OTHER_NE_SO) : $(OTHER_NE_SO_GZ) ; zcat $^ > $@
$(EE_SO)       : $(EE_SO_GZ)       ; zcat $^ > $@
$(STAG_SO)     : $(STAG_SO_GZ)     ; zcat $^ > $@

$(MEDIE_INPUT_XML) : $(MEDIE_INPUT_XML_GZ) ; zcat $^ > $@

##******************************************************************************
##
## 2.1.1: Import & clip
##
##******************************************************************************
ifeq (1,$(DO_IMPORT))

##------------------------------------------------------------------------------
## Import: *.xml -> (*.so.gz, *.txt.gz) with md5 value check if md5 file exists
##------------------------------------------------------------------------------
$(PUBMED_TXT_GZ) : $(PUBMED_SO_GZ)
$(PUBMED_SO_GZ)  : $(PUBMED_XML_GZ)
	@$(BEGIN_STEP)
	if [ -e $(PUBMED_XML_GZ_MD5) ]; \
	then \
		SUM1=`$(MD5) $(PUBMED_XML_GZ) | awk '{print $$1}'`; \
		SUM2=`awk '{print $$NF}' < $(PUBMED_XML_GZ_MD5)`; \
		if [ $$SUM1 = $$SUM2 ]; then true; \
		else echo "xml check sum differ" 1>&2; exit 1; fi \
	fi
	zcat $(PUBMED_XML_GZ) \
		| $(SOM) import - $(PUBMED_SO_GZ).ungz $(PUBMED_TXT_GZ).ungz \
		; $(PCHECK)
	$(MY_GZIP) $(PUBMED_SO_GZ)
	$(MY_GZIP) $(PUBMED_TXT_GZ)
	@$(END_STEP)

##------------------------------------------------------------------------------
## Clip
##------------------------------------------------------------------------------
$(ABST_TXT_GZ) : $(ABST_SO_GZ)
$(ABST_SO_GZ)  : $(PUBMED_TXT) $(PUBMED_SO_GZ)
	@$(BEGIN_STEP)
	zcat $(PUBMED_SO_GZ) \
		| $(SOM) clip - $(PUBMED_TXT) $(CLIP_TAG) \
		                $(ABST_SO_GZ).ungz $(ABST_TXT_GZ).ungz \
		; $(PCHECK)
	$(MY_GZIP) $(ABST_SO_GZ)
	$(MY_GZIP) $(ABST_TXT_GZ)
	@$(END_STEP)

endif ## ifeq (1,$(DO_IMPORT))
##******************************************************************************
## End of 2.1.1: Import & clip
##******************************************************************************


##******************************************************************************
##
## 2.1.2: Extraction of added/updated text
##
##******************************************************************************
ifeq (1,$(DO_EX_TXT))

##------------------------------------------------------------------------------
## Text region table -- common to weekly/annual update
##------------------------------------------------------------------------------
$(TXT_TBL_GZ) : $(PUBMED_SO_GZ) $(PUBMED_TXT_GZ)
	@$(BEGIN_STEP)
	$(MAKE_ARTICLE_TABLE) $(PUBMED_SO_GZ) $(PUBMED_TXT_GZ) \
		| gzip -c > $@ \
		; $(PCHECK)
	@$(END_STEP)

##------------------------------------------------------------------------------
## Extraction of added/updated text; the dependency on $(TXT_TBL_GZ) is only 
## for creating it in the course of weekly/annual processing
##------------------------------------------------------------------------------
ifeq (1,$(WEEKLY_UPDATE))
##------------------------------------------------------------------------------
## weekly update
##------------------------------------------------------------------------------
$(EX_TXT_GZ) : $(SO_SRC_GZ)
$(DEL_GZ)    : $(SO_SRC_GZ)
$(SO_SRC_GZ) : $(PUBMED_SO_GZ) $(PUBMED_TXT_GZ) $(CURR_BASELINE_TBL_GZ) \
               $(TXT_TBL_GZ)
	@$(BEGIN_STEP)
	$(MAKE_ENJU_SRC) $(CURR_OUT_DIR_BASE) $(PUBMED_SO_GZ) $(PUBMED_TXT_GZ) \
					 $(CURR_BASELINE_TBL_GZ) $(FIRST_UPDATE_ID)\
		             $(SO_SRC_GZ) $(EX_TXT_GZ) $(DEL_GZ) \
		|| ($(RM) -f $(SO_SRC_GZ) $(EX_TXT_GZ) $(DEL_GZ); exit 1)
	@$(END_STEP)
else
##------------------------------------------------------------------------------
## annual update
##------------------------------------------------------------------------------
$(EX_TXT_GZ) : $(SO_SRC_GZ)
$(SO_SRC_GZ) : $(PUBMED_SO_GZ) $(PUBMED_TXT_GZ) $(PREV_ALL_TBL_GZ) \
               $(TXT_TBL_GZ)
	@$(BEGIN_STEP)
	$(MAKE_ENJU_SRC) $(PREV_OUT_DIR_BASE) $(PUBMED_SO_GZ) $(PUBMED_TXT_GZ) \
	                 $(PREV_ALL_TBL_GZ) $(SO_SRC_GZ) $(EX_TXT_GZ) \
		|| ($(RM) -f $(SO_SRC_GZ) $(EX_TXT_GZ); exit 1)
	@$(END_STEP)	
endif ## ifeq (1,$(WEEKLY_UPDATE))

endif ## ifeq (1,$(DO_EX_TXT))
##******************************************************************************
## End of 2.1.2: Extraction of added/updated text
##******************************************************************************


##******************************************************************************
##
## 2.1.3: Sentence splitting
##
##******************************************************************************
ifeq (1,$(DO_SS))

##------------------------------------------------------------------------------
## sentence splitting for abst.txt
##------------------------------------------------------------------------------
$(ABST_SS_GZ) : $(ABST_TXT)
	@$(BEGIN_STEP)
	$(GENIASS) $(ABST_TXT) $@.ungz $(RUBY)
	$(MY_GZIP) $@
	@$(END_STEP)

##------------------------------------------------------------------------------
## sentence splitting for ex.txt
##------------------------------------------------------------------------------
$(EX_SS_GZ) : $(EX_TXT)
	@$(BEGIN_STEP)
	$(GENIASS) $(EX_TXT) $@.ungz $(RUBY)
	$(MY_GZIP) $@
	@$(END_STEP)

##------------------------------------------------------------------------------
## map file creation for abst.txt
##------------------------------------------------------------------------------
$(ABST_SS_MAP) : $(ABST_SS_GZ) $(ABST_TXT) 
	@$(BEGIN_STEP)
	zcat $(ABST_SS_GZ) \
		| $(MAKE_MAPPING) $(ABST_TXT) /dev/stdin > $@ \
		; $(PCHECK)
	@$(END_STEP)

##------------------------------------------------------------------------------
## map file creation for ex.txt
##------------------------------------------------------------------------------
$(EX_SS_MAP) : $(EX_SS_GZ) $(EX_TXT)
	@$(BEGIN_STEP)
	zcat $(EX_SS_GZ) \
		| $(MAKE_MAPPING) $(EX_TXT) /dev/stdin > $@ \
		; $(PCHECK)
	@$(END_STEP)

endif ## ifeq (1,$(DO_SS))
##******************************************************************************
## End of 2.1.3: Sentence splitting
##******************************************************************************


##******************************************************************************
##
## 2.1.4: HPSG Parsing
##
##******************************************************************************

##******************************************************************************
##
## 2.1.4.a: ex.txt parsing on a single machine
##
##******************************************************************************
ifeq (0,$(PARALLEL_PARSING))
ifeq (1,$(DO_EX_ENJU))
##------------------------------------------------------------------------------
## parsing with enju
##------------------------------------------------------------------------------
$(EX_SS_ENJU_SO_GZ) : $(EX_SS_GZ)
	@$(BEGIN_STEP)
	zcat $(EX_SS_GZ) | $(ENJU) | gzip -c > $@ ; $(PCHECK)
	@$(END_STEP)

##------------------------------------------------------------------------------
## post-processing
##------------------------------------------------------------------------------
$(EX_ENJU_SO_GZ) : $(EX_SS_ENJU_SO_GZ) $(EX_SS_MAP) 
	@$(BEGIN_STEP)
	zcat $(EX_SS_ENJU_SO_GZ) \
		| $(REMAP_STAND_OFF) /dev/stdin $(EX_SS_MAP) \
		| $(ADD_LEX_HEAD) \
		| gzip > $@ \
		; $(PCHECK)
	@$(END_STEP)
endif # ifeq (1,$(DO_EX_ENJU))

ifeq (1,$(DO_ENJU))
##------------------------------------------------------------------------------
## cut & paste & offset-shift of new/old parse result
##------------------------------------------------------------------------------
## Base directory of previous enju.so.dat files
ifeq (1,$(WEEKLY_UPDATE))
PREV_ENJU_SO_BASE = $(CURR_OUT_DIR_BASE)
else
PREV_ENJU_SO_BASE = $(PREV_OUT_DIR_BASE)
endif

$(ENJU_SO_RAW_GZ) : $(SO_SRC_GZ) $(EX_ENJU_SO_GZ)
	@$(BEGIN_STEP)
	$(MAKE_ENJU_SO) -s $(SO_SRC_GZ) -e $(EX_ENJU_SO_GZ) \
	                -b $(PREV_ENJU_SO_BASE) -x $(ENJU_SO_SUFFIX) \
		| gzip > $@ \
		; $(PCHECK)
	@$(END_STEP)

endif ## ifeq (1,$(DO_ENJU))
endif ## ifeq (0,$(PARALLEL_PARSING))

##******************************************************************************
## End of 2.1.4.a: ex.txt parsing on a single machine
##******************************************************************************

##******************************************************************************
##
## 2.1.4.b: parallel HPSG parsing
##
##******************************************************************************
ifeq (1,$(PARALLEL_PARSING))
ifeq (1,$(DO_ENJU))

##------------------------------------------------------------------------------
## File division: at most $(SUBFILE_MAX_LINE) lines (default: 2000) in one file
##------------------------------------------------------------------------------
SUBFILE_PREFIX = $(basename $(ABST_SS_GZ))
SUBFILE_SET    = $(SUBFILE_PREFIX).[0-9][0-9][0-9][0-9]
SUBFILE_GZ_SET = $(SUBFILE_PREFIX).[0-9][0-9][0-9][0-9].gz
SUBFILE_0      = $(SUBFILE_PREFIX).0000  ## the name of the first subfile
SUBFILE_MAX_LINE  = 100
MAX_PARALLEL_PROC = 500

$(SUBFILE_LIST) : $(ABST_SS_GZ)
	@$(BEGIN_STEP)
	$(RM) -f $(SUBFILE_SET) $(SUBFILE_GZ_SET) $(READY_TO_MERGE)
	(\
		(zcat $(ABST_SS_GZ) \
			| split -a 4 -l $(SUBFILE_MAX_LINE) -d - $(SUBFILE_PREFIX). ) \
		&& if [ -e $(SUBFILE_0) ]; then true ; else touch $(SUBFILE_0); fi \
		&& (echo $(SUBFILE_SET)    | xargs -n 1 gzip ; $(PCHECK)) \
		&& (echo $(SUBFILE_GZ_SET) | xargs -n 1 echo ; $(PCHECK)) > $@ \
	) || ($(RM) -f $(SUBFILE_SET) $(SUBFILE_GZ_SET) $@ ; exit 1)
	@$(END_STEP)

##------------------------------------------------------------------------------
## Parallel parsing
##------------------------------------------------------------------------------

## memo: 'lastword' function cannot be used in gmake ver 3.80 (?)
# LAST_MAKEFILE=$(lastword $(MAKEFILE_LIST))
MAKEFILE_LIST_GREP=$(shell echo $(MAKEFILE_LIST) | tr " " "\n" | grep '[mM]akefile')
LAST_MAKEFILE=$(word $(words $(MAKEFILE_LIST_GREP)),$(MAKEFILE_LIST_GREP))

$(READY_TO_MERGE) : $(SUBFILE_LIST)
	@$(BEGIN_STEP)
#	cat $(SUBFILE_LIST) \
#		| sed 's/gz$$/enju.gz/' \
#		| xargs -n $(MAX_PARALLEL_PROC) $(MAKE) -f $(LAST_MAKEFILE)
	sed 's/gz$$/enju.gz/' $(SUBFILE_LIST)
	$(MAKE) -f $(LAST_MAKEFILE) `sed 's/gz$$/enju.gz/' $(SUBFILE_LIST)`
	touch $(READY_TO_MERGE)
	@$(END_STEP)

$(OUT_DIR)/%.enju.gz : $(OUT_DIR)/%.gz
	zcat $< | nice -19 $(ENJU) | gzip > $@ ; $(PCHECK)

##------------------------------------------------------------------------------
## Merge the parse results
##------------------------------------------------------------------------------
$(ABST_SS_ENJU_SO_GZ) : $(SUBFILE_LIST) $(READY_TO_MERGE)
	@$(BEGIN_STEP)
	((cat $(SUBFILE_LIST) | sed 's/\.gz$$/.enju.gz/g'); cat $(SUBFILE_LIST)) \
		| $(MERGE_ENJU_OUTPUT) | gzip > $@ ; $(PCHECK)
	@$(END_STEP)

##------------------------------------------------------------------------------
## 1. Adjust offsets (REMAP_STAND_OFF)
## 2. Post-processing (ADD_LEX_HEAD)
## 3. Unite operation (SOM unite)
##------------------------------------------------------------------------------
$(ENJU_SO_RAW_GZ) : $(ABST_SS_ENJU_SO_GZ) $(ABST_SS_MAP) $(ABST_SO)
	@$(BEGIN_STEP)
	zcat $(ABST_SS_ENJU_SO_GZ) \
		| $(REMAP_STAND_OFF) /dev/stdin $(ABST_SS_MAP) \
		| $(ADD_LEX_HEAD) \
		| $(SOM) unite $(ABST_SO) - - \
		| gzip > $@ \
		; $(PCHECK)
	@$(END_STEP)

endif ## ifeq (1,$(DO_ENJU))
endif ## ifeq (1,$(PARALLEL_PARSING))
##******************************************************************************
## End of 2.1.4.b: parallel parsing
##******************************************************************************

##------------------------------------------------------------------------------
## Indexing of enju parse results -- common to parallel/single parsing
##------------------------------------------------------------------------------
ifeq (1,$(DO_ENJU))

$(ENJU_SO_IDX) : $(ENJU_SO_RAW_GZ)
$(ENJU_SO_DAT) : $(ENJU_SO_RAW_GZ)
	@$(BEGIN_STEP)
	$(MAKE_ENJU_SO_IDX) $(PUBMED_SO_GZ) $(ENJU_SO_RAW_GZ) \
	                    $(ENJU_SO_IDX) $(ENJU_SO_DAT) \
		|| ($(RM) -f $(ENJU_SO_IDX) $(ENJU_SO_DAT); exit 1)
	@$(END_STEP)

endif ## ifeq (1,$(DO_ENJU))


##******************************************************************************
##
## 2.1.5: Kenji's dependency parser
##
##******************************************************************************

##******************************************************************************
## persimonious parsing, on a single machine
##******************************************************************************
ifeq (0,$(PARALLEL_PARSING))
ifeq (1,$(DO_KSDEP))

$(EX_SS_KSDEP_OUT_GZ) : $(EX_SS_GZ)
	@$(BEGIN_STEP)
	zcat $(EX_SS_GZ) \
		| $(GENIA_TAGGER) \
		| $(POS2CONLL) \
		| $(KSDEP) -m $(KSDEP_MODEL) \
		| gzip > $@ \
		; $(PCHECK) 
	@$(END_STEP)

$(EX_SS_KSDEP_SO_GZ) : $(EX_SS_KSDEP_OUT_GZ) $(EX_SS)
	@$(BEGIN_STEP)
	zcat $(EX_SS_KSDEP_OUT_GZ) \
		| $(DEP2SO) - $(EX_SS) \
		| gzip > $@ \
		; $(PCHECK)
	@$(END_STEP)

$(EX_KSDEP_SO_GZ) : $(EX_SS_KSDEP_SO_GZ) $(EX_SS_MAP) 
	@$(BEGIN_STEP)
	zcat $(EX_SS_KSDEP_SO_GZ) \
		| $(REMAP_STAND_OFF) /dev/stdin $(EX_SS_MAP) \
		| gzip > $@ \
		; $(PCHECK)
	@$(END_STEP)

##------------------------------------------------------------------------------
## cut & paste & offset-shift of new/old parse result
##------------------------------------------------------------------------------
## Base directory of previous ksdep.so.dat files
ifeq (1,$(WEEKLY_UPDATE))
PREV_KSDEP_SO_BASE = $(CURR_OUT_DIR_BASE)
else
PREV_KSDEP_SO_BASE = $(PREV_OUT_DIR_BASE)
endif

$(KSDEP_SO_RAW_GZ) : $(SO_SRC_GZ) $(EX_KSDEP_SO_GZ)
	@$(BEGIN_STEP)
	$(MAKE_ENJU_SO) -s $(SO_SRC_GZ) -e $(EX_KSDEP_SO_GZ) \
	                -b $(PREV_KSDEP_SO_BASE) -x $(KSDEP_SO_SUFFIX) \
		| gzip > $@ \
		; $(PCHECK)
	@$(END_STEP)

endif ## ifeq (1,$(DO_KSDEP))
endif ## ifeq (0,$(PARALLEL_PARSING))

##******************************************************************************
## non-persimonious parsing
##******************************************************************************
ifeq (1,$(PARALLEL_PARSING))
ifeq (1,$(DO_KSDEP))

$(ABST_SS_KSDEP_OUT_GZ) : $(ABST_SS_GZ)
	@$(BEGIN_STEP)
	zcat $(ABST_SS_GZ) \
		| $(GENIA_TAGGER) \
		| $(POS2CONLL) \
		| $(KSDEP) -m $(KSDEP_MODEL) \
		| gzip > $@ \
		; $(PCHECK) 
	@$(END_STEP)

$(ABST_SS_KSDEP_SO_GZ) : $(ABST_SS_KSDEP_OUT_GZ) $(ABST_SS)
	@$(BEGIN_STEP)
	zcat $(ABST_SS_KSDEP_OUT_GZ) \
		| $(DEP2SO) - $(ABST_SS) \
		| gzip > $@ \
		; $(PCHECK)
	@$(END_STEP)

$(KSDEP_SO_RAW_GZ) : $(ABST_SS_KSDEP_SO_GZ) $(ABST_SS_MAP) $(ABST_SO)
	@$(BEGIN_STEP)
	zcat $(ABST_SS_KSDEP_SO_GZ) \
        | $(REMAP_STAND_OFF) /dev/stdin $(ABST_SS_MAP) \
        | $(SOM) unite $(ABST_SO) - - \
        | gzip > $@ \
        ; $(PCHECK)
	@$(END_STEP)

endif ## ifeq (1,$(DO_KSDEP))
endif ## ifeq (1,$(PARALLEL_PARSING))

##******************************************************************************
## Indexing of enju parse results -- common to parallel/single parsing
##******************************************************************************
ifeq (1,$(DO_KSDEP))

$(KSDEP_SO_IDX) : $(KSDEP_SO_RAW_GZ)
$(KSDEP_SO_DAT) : $(KSDEP_SO_RAW_GZ)
	@$(BEGIN_STEP)
	$(MAKE_ENJU_SO_IDX) $(PUBMED_SO_GZ) $(KSDEP_SO_RAW_GZ) \
	                    $(KSDEP_SO_IDX) $(KSDEP_SO_DAT) \
		|| ($(RM) -f $(KSDEP_SO_IDX) $(KSDEP_SO_DAT); exit 1)
	@$(END_STEP)

endif ## ifeq (1,$(DO_KSDEP))

##******************************************************************************
## End of 2.1.5: Kenji's dependency parser
##******************************************************************************


##******************************************************************************
##
## 2.1.6: Gene NER
##
##******************************************************************************
ifeq (1,$(DO_GENE_NE))

##------------------------------------------------------------------------------
## Gene NE tagging - Step 1: Dictionary matching
##------------------------------------------------------------------------------
$(GENE_NE_FILTER_SO) : $(PUBMED_TXT) $(ENJU_SO_DAT) $(PUBMED_SO)
	@$(BEGIN_STEP)
	zcat $(ENJU_SO_DAT) \
        | $(SOM) merge2 -t $(TAG_ORDER) - $(PUBMED_SO) - \
        | $(GENE_NER) $(PUBMED_TXT) - $@ $(GENE_NER_FILTER_OPTS) \
        ; $(PCHECK)
	@$(END_STEP)

##------------------------------------------------------------------------------
## Gene NE tagging - Step 2: Disambiguation
##------------------------------------------------------------------------------
$(GENE_NE_DISAMB_SO) : $(GENE_NE_FILTER_SO) $(PUBMED_TXT) $(ENJU_SO_DAT) $(PUBMED_SO)
	@$(BEGIN_STEP)
	zcat $(ENJU_SO_DAT) \
        | $(SOM) merge2 -t $(TAG_ORDER) $(GENE_NE_FILTER_SO) - $(PUBMED_SO) - \
        | $(GENE_NER) $(PUBMED_TXT) - - $(GENE_NER_DISAMB_OPTS) \
        | $(SORT_BY_ARTICLE) $(PUBMED_SO) > $@ \
        ; $(PCHECK)
	@$(END_STEP)

##------------------------------------------------------------------------------
## Gene NE tagging - Step 3: Filtering
##------------------------------------------------------------------------------
$(GENE_NE_ALL_SO_GZ) : $(GENE_NE_DISAMB_SO) $(PUBMED_TXT) $(ENJU_SO_DAT) $(PUBMED_SO)
	@$(BEGIN_STEP)
	zcat $(ENJU_SO_DAT) \
        | $(SOM) merge2 -t $(TAG_ORDER) $(GENE_NE_DISAMB_SO) - $(PUBMED_SO) - \
        | $(NER_POST_FILTER) $(PUBMED_TXT) - - $(NER_POST_FILTER_OPTS) \
        | $(MERGE_GENA_DATA) $(GENA_DICT_DIR) \
        | gzip -c > $@ \
        ; $(PCHECK)
	@$(END_STEP)

##------------------------------------------------------------------------------
## Gene NE tagging - Step 4: Thresholding
##------------------------------------------------------------------------------
$(GENE_NE_SO_GZ) : $(GENE_NE_ALL_SO_GZ)
	@$(BEGIN_STEP)
	zcat $(GENE_NE_ALL_SO_GZ) \
		| $(GENE_NE_THRESHOLD_FILTER) $(GENE_NE_THRESHOLD) \
		| gzip -c > $@ \
		; $(PCHECK)
	@$(END_STEP)

endif ## ifeq (1,$(DO_GENE_NE))
##******************************************************************************
## End of 2.1.6: Gene NER
##******************************************************************************


##******************************************************************************
##
## 2.1.7: Other NER - disease, symptom, etc.
##
##******************************************************************************
ifeq (1,$(DO_OTHER_NE))

##------------------------------------------------------------------------------
## Step 1: Dictionary matching
##------------------------------------------------------------------------------
$(OTHER_NE_MATCH_SO) : $(PUBMED_TXT) $(ENJU_SO_DAT)
	@$(BEGIN_STEP)
	zcat $(ENJU_SO_DAT) \
		| $(EXTRACT_SENTENCE_TEXT) $(PUBMED_TXT) - \
        | $(OTHER_NER) \
        | $(SOM) sort - $@ \
        ; $(PCHECK)
	@$(END_STEP)

##------------------------------------------------------------------------------
## Step 2: Filtering
##------------------------------------------------------------------------------
$(OTHER_NE_SO_GZ) : $(PUBMED_TXT) $(ENJU_SO_DAT) $(PUBMED_SO) $(OTHER_NE_MATCH_SO)
	@$(BEGIN_STEP)
	zcat $(ENJU_SO_DAT) \
        | $(SOM) merge2 -t $(TAG_ORDER) $(OTHER_NE_MATCH_SO) - $(PUBMED_SO) - \
        | $(NER_POST_FILTER) $(PUBMED_TXT) - - $(NER_POST_FILTER_OPTS) \
        | gzip -c > $@ \
        ; $(PCHECK)
	@$(END_STEP)

endif ## ifeq (1,$(DO_OTHER_NE))
##******************************************************************************
## End of 2.1.7: Other NER - disease, symptom, etc.
##******************************************************************************


##******************************************************************************
##
## 2.1.8: Merge operations
##
##******************************************************************************
ifeq (1,$(DO_MERGE))

$(ALL_NE_SO) : $(GENE_NE_SO_GZ) $(OTHER_NE_SO)
	@$(BEGIN_STEP)
	zcat $(GENE_NE_SO_GZ) \
		| $(SOM) merge2 -t $(TAG_ORDER) - $(OTHER_NE_SO) $@ \
		; $(PCHECK)
	@$(END_STEP)

$(ENJU_NE_SO_GZ) : $(ENJU_SO_DAT) $(ALL_NE_SO)
	@$(BEGIN_STEP)
	zcat $(ENJU_SO_DAT) \
		| $(SOM) merge2 -t $(TAG_ORDER) - $(ALL_NE_SO) - \
		| gzip > $@ \
		; $(PCHECK)
	@$(END_STEP)

$(PUBMED_ENJU_NE_SO_GZ) : $(ENJU_NE_SO_GZ) $(PUBMED_SO)
	@$(BEGIN_STEP)
	zcat $(ENJU_NE_SO_GZ) \
		| $(SOM) merge2 -t $(TAG_ORDER) - $(PUBMED_SO) - \
		| gzip > $@ \
		; $(PCHECK)
	@$(END_STEP)

endif ## ifeq (1,$(DO_MERGE))
##******************************************************************************
## End of 2.1.8: Merge operations
##******************************************************************************


################################################################################
##
## Section 2.2: Rules for MEDIE
##
################################################################################

##------------------------------------------------------------------------------
## Event expression tagging
##------------------------------------------------------------------------------
ifeq (1,$(DO_EE))

$(EE_SO_GZ) : $(ENJU_SO_DAT) $(EE_TAGGER_DICT)
	@$(BEGIN_STEP)
	zcat $(ENJU_SO_DAT) \
		| $(EE_TAGGER) $(EE_TAGGER_CONF) $(EE_TAGGER_DICT) \
		| gzip > $@ \
		; $(PCHECK)
	@$(END_STEP)

endif ## ifeq (1,$(DO_EE))

##------------------------------------------------------------------------------
## Sentence tagging
##------------------------------------------------------------------------------
ifeq (1,$(DO_STAG))

$(STAG_SO_GZ) : $(PUBMED_ENJU_NE_SO_GZ) $(PUBMED_TXT)
	@$(BEGIN_STEP)
	$(MAKE_STAGGER_INPUT) $(PUBMED_TXT) $(PUBMED_ENJU_NE_SO_GZ) \
		| $(STAGGER) > $@.tmp.output \
		; $(PCHECK)
	zcat $(PUBMED_ENJU_NE_SO_GZ) \
		| $(MERGE_STAGGER_OUTPUT) $@.tmp.output \
		| gzip > $@ \
		; $(PCHECK)
	$(RM) $@.tmp.output
	@$(END_STEP)

endif ## ifeq (1,$(DO_STAG))

##------------------------------------------------------------------------------
## Bibliographical data
##------------------------------------------------------------------------------
ifeq (1,$(DO_BIB))

$(BIB_SO) : $(PUBMED_SO_GZ) $(PUBMED_TXT)
	@$(BEGIN_STEP)
	zcat $(PUBMED_SO_GZ) \
		| $(BIB_TAGGER) $(PUBMED_TXT) > $@ \
		; $(PCHECK)
	@$(END_STEP)

endif ## ifeq (1,$(DO_BIB))

##------------------------------------------------------------------------------
##  1. Merge pubmed_enju_ne + ee + stag + bib (SOM merge2) 
##     (delete ifactor: 2008.12, matuzaki)
##  2. ID-assignment-scheme modification (CHANGE_ID)
##  3. Make the tag names etc. backward-compatible (COMPATIBLE)
##------------------------------------------------------------------------------
ifeq (1,$(DO_MEDIE_INPUT))

# $(IFACTOR_TXT) : $(PUBMED_SO_GZ) $(PUBMED_XML_GZ) $(SRC_IFACTOR_FILE)
#	$(CREATE_IFACTOR) -m $(FILE_ID) -x $(PUBMED_XML_GZ) -s $(PUBMED_SO_GZ) \
#	                  -i $(SRC_IFACTOR_FILE) -o $(IFACTOR_TXT)	 

MEDIE_ADDITIONAL_SO = $(EE_SO) $(STAG_SO) $(BIB_SO)

$(MEDIE_INPUT_SO_GZ) : $(PUBMED_ENJU_NE_SO_GZ) $(MEDIE_ADDITIONAL_SO)
	@$(BEGIN_STEP)
	zcat $(PUBMED_ENJU_NE_SO_GZ) \
		| $(SOM) merge2 -t $(TAG_ORDER) - $(MEDIE_ADDITIONAL_SO) - \
		| $(CHANGE_ID) \
		| $(COMPATIBLE) $(FILE_ID) \
		| gzip > $@ \
		; $(PCHECK)
	@$(END_STEP)

##------------------------------------------------------------------------------
##  Export: Standoff -> XML
##------------------------------------------------------------------------------
$(MEDIE_INPUT_XML_GZ) : $(MEDIE_INPUT_SO_GZ) $(PUBMED_TXT)
	@$(BEGIN_STEP)
	zcat $(MEDIE_INPUT_SO_GZ) \
		| $(SOM) export - $(PUBMED_TXT) - \
		| gzip > $@ \
		; $(PCHECK)
	@$(END_STEP)

##------------------------------------------------------------------------------
##  MEDIE DB indexing
##------------------------------------------------------------------------------
$(MEDIE_DB_TIMESTAMP) : $(MEDIE_INPUT_XML)
	@$(BEGIN_STEP)
	$(RM) -f $(MEDIE_DB_TIMESTAMP)
	$(RM) -rf $(DB_OUT_DIR)
	mkdir -p $(DB_OUT_DIR)
	$(MAKE_DB) \
		-attrlist $(DB_ATTRLIST) \
		-setting  $(DB_SETTING) \
		-f        $(MEDIE_INPUT_XML) \
		-dbdir    $(DB_OUT_DIR) \
		> $(MAKE_DB_LOG) 2>&1
	touch $@
	@$(END_STEP)

endif ## ifeq (1,$(DO_MEDIE_INPUT))

################################################################################
##
## End of Section 2.2: Rules for MEDIE
##
################################################################################



################################################################################
##
## Section 2.3: Rules for Info-PubMed
##
################################################################################

##------------------------------------------------------------------------------
## Protein-Protein Interaction (PPI) recognition
##------------------------------------------------------------------------------
ifeq (1,$(DO_PPI))

### Memo: Current version of rune's PPI does not accept disease NEs.
###       We could use PUBMED_ENJU_NE_SO_GZ later.
###
$(PPI_INPUT_SO) : $(PUBMED_TXT) $(ENJU_SO_DAT) $(GENE_NE_SO) $(PUBMED_SO)
	@$(BEGIN_STEP)
	zcat $(ENJU_SO_DAT) \
		| $(SOM) merge2 -t $(TAG_ORDER) - $(GENE_NE_SO) $(PUBMED_SO) $@ \
		; $(PCHECK)
	@$(END_STEP)

$(RUNE_CONFIG_XML) : $(PUBMED_TXT) $(PPI_INPUT_SO) $(ENJU_SO) $(KSDEP_SO)  
	@$(BEGIN_STEP)
	$(RUNE_CONFIG) $(PUBMED_TXT) $(PPI_INPUT_SO) $(ENJU_SO) $(KSDEP_SO) \
	               $(PPI_INPUT_SO) $(AKANE_MODEL) $(OUT_DIR)/$(FILE_ID) > $@
	@$(END_STEP)

$(PPI_SO_GZ) : $(RUNE_CONFIG_XML) $(PPI_INPUT_SO) $(ENJU_SO) $(KSDEP_SO)
	@$(BEGIN_STEP)
	$(AKANE_PPI) script $(RUNE_CONFIG_XML) -C g 2> $(AKANE_LOG)
	$(RM) -f $(AKANE_LOG).gz
	$(RM) -f $(PPI_SO).gz
	gzip $(AKANE_LOG)
	gzip $(PPI_SO)
	@$(END_STEP)

endif ## ifeq (1,$(DO_PPI))


##------------------------------------------------------------------------------
## Disease-Gene Association (DGA) recognition
##------------------------------------------------------------------------------
ifeq (1,$(DO_DGA))

### Memo: ENJU_SO_DAT is required only for the workaround of dga's bug
$(DGA_SO_GZ) : $(PUBMED_ENJU_NE_SO_GZ) $(PUBMED_TXT) $(ENJU_SO_DAT)
	@$(BEGIN_STEP)
	# 2007.11.07: workaround for dga's bug (som sort)
	# 2007.11.07: another workaround for dga's bug (output_filter)
	zcat $(PUBMED_ENJU_NE_SO_GZ) \
		| $(DGA_INPUT_FILTER) \
		| $(DGA) /dev/stdin $(PUBMED_TXT) \
		| $(SOM) sort - - \
		| $(DGA_OUTPUT_FILTER) $(ENJU_SO_DAT) \
		| gzip > $@ \
		; $(PCHECK)
	@$(END_STEP)

endif ## ifeq (1,$(DO_DGA))

##------------------------------------------------------------------------------
## Co-occurrence extraction
##------------------------------------------------------------------------------
ifeq (1,$(DO_COOCC))

$(COOCC_SO_GZ) : $(PUBMED_ENJU_NE_SO_GZ)
	@$(BEGIN_STEP)
	zcat $(PUBMED_ENJU_NE_SO_GZ) \
		| $(FIND_COOCC) \
		| $(SOM) sort -t $(TAG_ORDER) - - \
		| gzip > $@ \
		; $(PCHECK)
	@$(END_STEP)

endif ## ifeq (1,$(DO_COOCC))

##------------------------------------------------------------------------------
## IConverter
##------------------------------------------------------------------------------
ifeq (1,$(DO_ICONVERTER))

$(ICONVERTER_INPUT_SO_GZ) : \
		$(PUBMED_ENJU_NE_SO_GZ) \
		$(PPI_SO_GZ) \
		$(DGA_SO_GZ) \
		$(COOCC_SO_GZ)
	@$(BEGIN_STEP)
	zcat $(PPI_SO_GZ) \
		| $(PPI_THRESHOLD_FILTER) $(PPI_THRESHOLD) \
		| perl -p -e 's/\s+id="[^"]*"//; s/\s+confidence="[^"]*"//; s/$$/ subtype="unknown"/;' \
		> $@.tmp.ppi.so \
		; $(PCHECK)
	zcat $(DGA_SO_GZ) > $@.tmp.dga.so
	zcat $(COOCC_SO_GZ) > $@.tmp.coocc.so
	zcat $(PUBMED_ENJU_NE_SO_GZ) \
		| $(SOM) merge2 -t $(TAG_ORDER) - \
			$@.tmp.ppi.so $@.tmp.dga.so $@.tmp.coocc.so - \
		| gzip > $@ \
		; $(PCHECK)
	$(RM) $@.tmp.ppi.so $@.tmp.dga.so $@.tmp.coocc.so
	@$(END_STEP)

$(PREOUT) : $(ICONVERTER_INPUT_SO_GZ) $(PUBMED_TXT)
	@$(BEGIN_STEP)
	zcat $(ICONVERTER_INPUT_SO_GZ) \
		| $(ICONVERTER) /dev/stdin $(PUBMED_TXT) $(FILE_ID) > $@ \
		; $(PCHECK)
	@$(END_STEP)

$(DELCIT) : $(PUBMED_SO_GZ) $(PUBMED_TXT)
	@$(BEGIN_STEP)
	$(COLLECT_DEL) $(PUBMED_SO_GZ) $(PUBMED_TXT) > $@
	@$(END_STEP)

endif ## ifeq (1,$(DO_ICONVERTER))

################################################################################
##
## End of Section 2.3: Rules for Info-PubMed
##
################################################################################


################################################################################
##
## Section 2.4: Rules for export data
##
################################################################################
ifeq (1,$(DO_EXPORT))

##------------------------------------------------------------------------------
## Update summary record:
##   [XML time-stamp] [# of new article] [# of updated article] [# of deleted article]
##------------------------------------------------------------------------------
ifeq (1,$(WEEKLY_UPDATE))
$(UPDATE_SUMMARY) : $(TXT_TBL_GZ) $(DEL_GZ) $(DELCIT) $(PUBMED_XML_GZ)
	@$(BEGIN_STEP)
#	DATE=`perl -e 'print scalar(localtime((stat "$(PUBMED_XML_GZ)")[9]))'`; \
#	NUM_TOTAL=`zcat $(TXT_TBL_GZ) | wc -l | awk '{print $$1}'`; \
#	NUM_UPD_DEL=`zcat $(DEL_GZ)   | wc -l | awk '{print $$1}'`; \
#	NUM_DEL=`cat $(DELCIT)        | wc -l | awk '{print $$1}'`; \
#	NUM_UPD=`echo $$(($$NUM_UPD_DEL - $$NUM_DEL))`; \
#	NUM_NEW=`echo $$(($$NUM_TOTAL - $$NUM_UPD_DEL))`; \
#	printf "%s\t%d\t%d\t%d\n" "$$DATE" $$NUM_NEW $$NUM_UPD $$NUM_DEL > $@
	$(MAKE_SUMMARY_REC) -u $(TXT_TBL_GZ) $(PUBMED_XML_GZ) $(DEL_GZ) $(DELCIT) > $@
	@$(END_STEP)
else
$(UPDATE_SUMMARY) : $(TXT_TBL_GZ) $(PUBMED_XML_GZ)
	@$(BEGIN_STEP)
#	DATE=`perl -e 'print scalar(localtime((stat "$(PUBMED_XML_GZ)")[9]))'`; \
#	NUM_NEW=`zcat $(TXT_TBL_GZ) | wc -l | awk '{print $$1}'`; \
#	printf "%s\t%d\t%d\t%d\n" "$$DATE" $$NUM_NEW 0 0 > $@
	$(MAKE_SUMMARY_REC) -b $(TXT_TBL_GZ) $(PUBMED_XML_GZ) > $@
	@$(END_STEP)
endif # ifeq (1,$(WEEKLY_UPDATE))

##------------------------------------------------------------------------------
## Export-tarball
##------------------------------------------------------------------------------
GET_FULL_PATH = perl -nae 'print(m{^/} ? "" : "$(PWD)/", "$$_\n") foreach (@F)'

EXPORT_DEP_FILES = $(PREOUT) $(UPDATE_SUMMARY) $(PUBMED_TXT_GZ) $(MEDIE_DB_TIMESTAMP)
EXPORTED_FILES_R = $(PREOUT) $(UPDATE_SUMMARY) $(PUBMED_TXT_GZ) $(DB_OUT_DIR)

ifeq (1,$(WEEKLY_UPDATE))
EXPORT_DEP_FILES += $(DELCIT) $(DEL_GZ)
EXPORTED_FILES_R += $(DELCIT) $(DEL_GZ)
endif

EXPORTED_FILES = $(shell echo $(EXPORTED_FILES_R) | $(GET_FULL_PATH))
EXPORT_WORK_DIR = $(WORK_BASE)/$(FILE_ID)

$(EXPORT_TGZ) : $(EXPORT_DEP_FILES)
	@$(BEGIN_STEP)
	$(RM) -rf   $(EXPORT_WORK_DIR)
	mkdir -p $(dir $@)
	mkdir -p $(EXPORT_WORK_DIR)
	for f in $(EXPORTED_FILES); do ln -s $$f $(EXPORT_WORK_DIR)/; done
	tar hcvzf $@ -C $(EXPORT_WORK_DIR)/.. $(FILE_ID)
	$(RM) -rf $(EXPORT_WORK_DIR)
	@$(END_STEP)

endif ## ifeq (1,$(DO_EXPORT))

################################################################################
##
## End of Section 2.4: Rules for export data
##
################################################################################


################################################################################
##
## Section 2.A: Rules for merged txt-tbl
##
################################################################################
ifeq (1,$(DO_TBL))
##------------------------------------------------------------------------------
## Merge all records from baseline files
##------------------------------------------------------------------------------
$(CURR_BASELINE_TBL_GZ) :
	@$(BEGIN_STEP)
	mkdir -p $(dir $@)
	seq 1 $(LAST_BASELINE_ID) \
		| awk '{ printf "%s/medline$(YEAR)n%04d/medline$(YEAR)n%04d.txt-tbl.gz\n", \
		       "$(CURR_OUT_DIR_BASE)", $$1, $$1 }' \
		| $(MERGE_ARTICLE_TABLE) \
		| gzip -c > $@ \
		; $(PCHECK)
	@$(END_STEP)

##------------------------------------------------------------------------------
## Merge all records from last year's baseline files and update files
##------------------------------------------------------------------------------
$(PREV_ALL_TBL_GZ) :
	@$(BEGIN_STEP)
	mkdir -p $(dir $@)
	M=medline$(LAST_YEAR); echo $(PREV_OUT_DIR_BASE)/$${M}n????/$${M}n????.txt-tbl.gz \
		| xargs -n 1 echo \
		| $(MERGE_ARTICLE_TABLE) \
		| gzip -c > $@ \
		; $(PCHECK)
	@$(END_STEP)
endif ## ifeq (1,$(DO_TBL))
################################################################################
##
## End of Section 2.A: Rules for merged txt-tbl
##
################################################################################

# vim: set noexpandtab :
